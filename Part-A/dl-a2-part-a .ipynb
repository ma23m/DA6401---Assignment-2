{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "key = input('Enter your API:')\n",
    "wandb.login(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Choose GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 1. Data Loading and Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to fixed size\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization\n",
    "])\n",
    "\n",
    "# Load training and testing datasets\n",
    "train_data = ImageFolder(root='/kaggle/input/inaturalist-dataset/inaturalist_12K/train', transform=transform)\n",
    "test_data = ImageFolder(root='/kaggle/input/inaturalist-dataset/inaturalist_12K/val', transform=transform)\n",
    "\n",
    "# Split train_data into training and validation sets (80-20 split)\n",
    "train_size = int(0.8 * len(train_data)) # Calculate 80%  data used for training\n",
    "val_size = len(train_data) - train_size # 20%  data used for validation\n",
    "train_dataset, val_dataset = random_split(train_data, [train_size, val_size]) # Split the dataset training and validation\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2) # Create DataLoaders for train\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)  # Create DataLoaders for  val\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=2) # Create DataLoaders for test\n",
    "\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_filters=None, kernel_size=3, \n",
    "                 activation='relu', dense_neurons=128, num_classes=10, \n",
    "                 dropout_rate=0.3, batch_norm=True, num_conv_layers=5, input_size=128):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.activation = activation  # Activation function to use\n",
    "        self.batch_norm = batch_norm  # Apply batch normalization\n",
    "        self.dropout_rate = dropout_rate # Dropout rate for regularization\n",
    "\n",
    "        # Define convolution filters \n",
    "        if num_filters is None:\n",
    "            num_filters = [32, 64, 128, 256, 512] # number of defults filters\n",
    "        elif isinstance(num_filters, int):\n",
    "            num_filters = [num_filters] * num_conv_layers # Repeat same filter count\n",
    "        elif isinstance(num_filters, list):\n",
    "            assert len(num_filters) >= num_conv_layers  # Ensure enough filters are defined\n",
    "\n",
    "        # Handle kernel_size as int or list\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = [kernel_size] * num_conv_layers # If kernel_size is a single integer convert it into a list with the same value repeated for each conv layer\n",
    "        elif isinstance(kernel_size, list):\n",
    "            assert len(kernel_size) >= num_conv_layers # If it is already a list, make sure it has enough values (at least one for each conv layer)\n",
    "        else:\n",
    "            raise TypeError(\"kernel_size must be a list or an integer.\") # Raise an error if kernel_size is neither an int nor a list\n",
    "\n",
    "        # Handle dense neurons as int or list\n",
    "        if isinstance(dense_neurons, int):\n",
    "            dense_neurons = [dense_neurons] # If it is a single number, convert it to a list with one element\n",
    "        elif isinstance(dense_neurons, list):\n",
    "            assert all(isinstance(x, int) for x in dense_neurons) # If it is a list, check that every element in the list is an integer\n",
    "        else:\n",
    "            raise TypeError(\"dense_neurons must be a list or an integer.\") # Raise an error if it is neither an int nor a list\n",
    "\n",
    "        # Build convolutional layers\n",
    "        layers = [] # Initialize an empty list to store convolutional blocks\n",
    "        in_channels = input_channels # Set the number of input channels (e.g., 3 for RGB images)\n",
    "        for i in range(num_conv_layers):\n",
    "            out_channels = num_filters[i] # Get the number of output filters \n",
    "            k_size = kernel_size[i] # Get the kernel size for this convolution  layer\n",
    "            layers.append(self.create_conv_block(in_channels, out_channels, k_size)) # Create a convolutional block and add the list\n",
    "            in_channels = out_channels # Set the input for the next layer to be the current output\n",
    "        self.conv_layers = nn.Sequential(*layers) # Combine convolution blocks into a sequence\n",
    "\n",
    "        # Dynamically calculate flattened size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, input_channels, input_size, input_size) # Create a fake image input (batch size 1) with given size\n",
    "            dummy_output = self.conv_layers(dummy_input) # Pass the dummy input through the convolution layers\n",
    "            self.flattened_size = dummy_output.view(1, -1).size(1) # Flatten the output and get the total number of features for the first dense layer\n",
    "\n",
    "        # Build fully connected (dense) layers\n",
    "        self.flatten = nn.Flatten() # Layer to flatten convolution output into 1D for the dense layers\n",
    "        fc_layers = [] # Initialize an empty list to store dense layers\n",
    "        in_features = self.flattened_size # Set input size for the first dense layer\n",
    "        for out_features in dense_neurons:\n",
    "            fc_layers.append(nn.Linear(in_features, out_features)) # Linear layer\n",
    "            fc_layers.append(self.get_activation())  # Activation function\n",
    "            fc_layers.append(nn.Dropout(self.dropout_rate)) # Dropout layer\n",
    "            in_features = out_features # Set the number of input features for the next dense layer to the current layer's output size\n",
    "        fc_layers.append(nn.Linear(in_features, num_classes))  # Final output layer\n",
    "        self.fc_layers = nn.Sequential(*fc_layers) # Combine all dense layers into a single sequential layer for the forward pass\n",
    "\n",
    "    # Create a single convolutional block\n",
    "    def create_conv_block(self, in_channels, out_channels, kernel_size):\n",
    "        padding = kernel_size // 2  # Same padding\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding)] # Create a convolutional layer\n",
    "        if self.batch_norm:\n",
    "            layers.append(nn.BatchNorm2d(out_channels)) # Batch normalization if enabled\n",
    "        layers.append(self.get_activation()) # Activation function\n",
    "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2)) # Downsample by 2\n",
    "        layers.append(nn.Dropout(self.dropout_rate)) # Dropout layer\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    # Choose activation function\n",
    "    def get_activation(self):\n",
    "        activations = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'gelu': nn.GELU(),\n",
    "            'silu': nn.SiLU(),\n",
    "            'mish': nn.Mish()\n",
    "        }\n",
    "        return activations.get(self.activation, nn.ReLU()) # Default to ReLU if not found\n",
    "\n",
    "    # Forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x) # Pass through conv layers\n",
    "        x = self.flatten(x) # Flatten before dense layers\n",
    "        x = self.fc_layers(x) # Pass through dense layers\n",
    "        return x\n",
    "\n",
    "\n",
    "# Get number of output classes\n",
    "num_classes = len(train_data.classes)\n",
    "\n",
    "# Create the model with custom configuration\n",
    "model = CustomCNN(\n",
    "    input_channels=3,\n",
    "    input_size=128,\n",
    "    num_classes=num_classes,\n",
    "    num_conv_layers=5,\n",
    "    num_filters=[32, 64, 128, 256, 512], # Define the number of filters for each convolutional layer\n",
    "    kernel_size=[3, 5, 3, 5, 1],  # Different kernel sizes for each conv layer\n",
    "    dense_neurons=[512, 256, 64] # Three fully connected layers before output\n",
    ").to(device) # Move model to GPU/CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config=None):\n",
    "    with wandb.init(config=config): # Initialize Weights & Biases for logging hyperparameters and metrics\n",
    "        config = wandb.config # Access the configuration set by Weights & Biases\n",
    "\n",
    "        # Create CNN model with hyperparameters\n",
    "        model = CustomCNN(\n",
    "            input_channels=3,\n",
    "            num_filters=config.num_filters,\n",
    "            activation=config.activation,\n",
    "            dense_neurons=128,\n",
    "            num_classes=10,\n",
    "            dropout_rate=config.dropout_rate,\n",
    "            batch_norm=config.batch_norm\n",
    "        ).to(device)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()# Cross-Entropy function use as a loss function for multi-class classification\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Set the Adam optimizer with a learning rate of 0.001\n",
    "\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(10):  # 10 epochs for demonstration\n",
    "            model.train() # Set the model to training mode\n",
    "            running_loss = 0.0 # Initialize a variable to track the running loss\n",
    "            correct, total = 0, 0 # Initialize counters for correct predictions and total samples\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device) # Move images and labels to the device (GPU/CPU)\n",
    "                optimizer.zero_grad() # Clear the gradients from the previous step\n",
    "                outputs = model(images) # Pass the images through the model to get predictions\n",
    "                loss = criterion(outputs, labels) # Backpropagate the loss to compute gradients\n",
    "                loss.backward() # Backpropagate the loss to compute gradients\n",
    "                optimizer.step() # Update the model's parameters based on gradients\n",
    "\n",
    "                running_loss += loss.item() # Add the current loss to the running loss\n",
    "                _, predicted = torch.max(outputs, 1) # Get the predicted class by choosing the highest output probability\n",
    "                total += labels.size(0) # Update the total number of labels\n",
    "                correct += (predicted == labels).sum().item() # Count the number of correct predictions\n",
    "\n",
    "\n",
    "            train_acc = 100 * correct / total # Calculate the training accuracy\n",
    "            val_acc, val_loss = evaluate_model(model, val_loader, criterion) # Evaluate the model on the validation data\n",
    "\n",
    "            print({'train_loss': running_loss / len(train_loader), 'train_accuracy': train_acc,\n",
    "                       'val_loss': val_loss, 'val_accuracy': val_acc})\n",
    "            # Log metrics\n",
    "            wandb.log({'train_loss': running_loss / len(train_loader), 'train_accuracy': train_acc,\n",
    "                       'val_loss': val_loss, 'val_accuracy': val_acc})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval() # Set model to evaluation mode (turn off dropout, batchnorm, etc.)\n",
    "    correct, total, running_loss = 0, 0, 0.0 # Initialize counters for correct predictions, total samples, and loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data in batches\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device) # Move data to the device (GPU or CPU)\n",
    "            outputs = model(images) # Get model predictions for the batch\n",
    "            loss = criterion(outputs, labels) # Calculate loss for this batch\n",
    "            running_loss += loss.item() # Accumulate the batch loss\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1) # Get the class with the highest score for each sample\n",
    "            total += labels.size(0) # Add number of samples in the batch to total\n",
    "            correct += (predicted == labels).sum().item() # Count how many predictions are correct\n",
    "\n",
    "\n",
    "    accuracy = 100 * correct / total # Calculate overall accuracy as a percentage\n",
    "    avg_loss = running_loss / len(data_loader) # Calculate average loss per batch\n",
    "    return accuracy, avg_loss # Return accuracy and average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sweep configuration dictionary\n",
    "sweep_config = {\n",
    "    'name': 'scratch_hyperparam_sweep-1',  # Name of the sweep\n",
    "    'method': 'bayes',  # Optimization method: could be 'grid', 'random', or 'bayes'\n",
    "    \n",
    "    # Metric to optimize during the sweep\n",
    "    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n",
    "    \n",
    "    # Hyperparameters to tune and their candidate values\n",
    "    'parameters': {\n",
    "        # Different filter combinations for CNN layers\n",
    "        'num_filters': {\n",
    "            'values': [\n",
    "                [16, 32, 64, 128, 256],      # Increasing filter sizes\n",
    "                [64, 64, 64, 64, 64],        # Same number of filters in each layer\n",
    "                [256, 128, 64, 32, 16],      # Decreasing filter sizes\n",
    "                [32, 32, 32, 32, 32],        # Uniform filters\n",
    "                [16, 32, 64, 32, 16]         # Symmetric pattern\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        # Activation functions to try\n",
    "        'activation': {'values': ['relu', 'gelu', 'silu', 'mish']},\n",
    "        \n",
    "        # Whether to use batch normalization or not\n",
    "        'batch_norm': {'values': [True, False]},\n",
    "        \n",
    "        # Dropout rate values to explore\n",
    "        'dropout_rate': {'values': [0.2, 0.3]},\n",
    "        \n",
    "        # Whether to apply data augmentation techniques\n",
    "        'data_augmentation': {'values': [True, False]},\n",
    "        \n",
    "        # How to organize filters: same as previous layer, double, or half\n",
    "        'filter_organization': {'values': ['same', 'double', 'half']},\n",
    "        \n",
    "        # Different kernel size combinations for convolution layers\n",
    "        'kernel_size': {\n",
    "            'values': [\n",
    "                [3, 3, 3, 3, 3],     # All 3x3 kernels\n",
    "                [3, 3, 5, 3, 3],     # One wider layer in the middle\n",
    "                [3, 5, 3, 5, 3],     # Alternating pattern\n",
    "                [5, 5, 5, 5, 5],     # All 5x5 kernels\n",
    "                [5, 7, 7, 3, 5]      # Mixed sizes\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        # Configurations for dense (fully connected) layers\n",
    "        'dense_neurons': {\n",
    "            'values': [\n",
    "                [512],                # Single dense layer with 512 units\n",
    "                [256],                # Single layer with fewer units\n",
    "                [128],                # Even fewer\n",
    "                [64, 128, 256],       # Multi-layer with increasing size\n",
    "                [512, 256, 64]        # Multi-layer with decreasing size\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Start the sweep on WandB with the defined configuration under project 'DL_A2'\n",
    "sweep_id = wandb.sweep(sweep_config, project='DL_A2')\n",
    "\n",
    "# Launch the sweep agent to run training 100 times with different hyperparameter combinations\n",
    "wandb.agent(sweep_id, train_model, count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define best config from sweep BEFORE wandb.init\n",
    "best_config = {\n",
    "    'name': 'Best_configuration_test_acc-1',\n",
    "    'num_filters':  [64,64,64,64,64],\n",
    "    'activation': 'gelu',\n",
    "    'dropout_rate': 0.2,\n",
    "    'batch_norm': True\n",
    "}\n",
    "\n",
    "#  Initialize wandb project\n",
    "wandb.init(\n",
    "    project=\"DL_A2\",  # project name\n",
    "    config=best_config,\n",
    "    name=\"best-model-run\",  # optional run name\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize the model with best config\n",
    "best_model = CustomCNN(\n",
    "    input_channels=3,\n",
    "    num_filters=best_config['num_filters'],\n",
    "    activation=best_config['activation'],\n",
    "    dense_neurons=128,\n",
    "    num_classes=len(train_data.classes),\n",
    "    dropout_rate=best_config['dropout_rate'],\n",
    "    batch_norm=best_config['batch_norm'],\n",
    "    num_conv_layers=len(best_config['num_filters'])\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # Use cross-entropy loss for classification\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=0.001) # Adam optimizer with learning rate\n",
    "\n",
    "# Train for N epochs\n",
    "for epoch in range(20):    # Train for 20 epochs\n",
    "    best_model.train() # Set model to training mode\n",
    "    running_loss, correct, total = 0.0, 0, 0 # Initialize metrics\n",
    "\n",
    "    for images, labels in train_loader: # Loop over training batches\n",
    "        images, labels = images.to(device), labels.to(device) # Move data to device\n",
    "        optimizer.zero_grad() # Clear previous gradients\n",
    "        outputs = best_model(images) # Forward pass\n",
    "        loss = criterion(outputs, labels) # Compute loss\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Update model weights\n",
    " \n",
    "        running_loss += loss.item() # Accumulate loss\n",
    "        _, predicted = torch.max(outputs, 1) # Get predicted class\n",
    "        total += labels.size(0) # Update total count\n",
    "        correct += (predicted == labels).sum().item() # Count correct predictions\n",
    "\n",
    "    train_acc = 100 * correct / total # Calculate training accuracy\n",
    "    val_acc, val_loss = evaluate_model(best_model, val_loader, criterion) # Evaluate on validation set\n",
    "\n",
    "    #  Log metrics to wandb\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"train_loss\": running_loss / len(train_loader),\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_loss\": val_loss\n",
    "     })\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\") # Print epoch summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model.eval() #Set model to evaluation mode (no dropout, no batchnorm updates)\n",
    "correct = 0 # Count of correct predictions\n",
    "total = 0  # Total number of test samples\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader: # Loop through test data\n",
    "        images, labels = images.to(device), labels.to(device) # Move data to GPU/CPU\n",
    "        outputs = best_model(images) # Get model predictions\n",
    "        _, preds = torch.max(outputs, 1) # Take the class with highest score\n",
    "        correct += (preds == labels).sum().item() # Count correct predictions\n",
    "        total += labels.size(0) # Count total samples\n",
    "\n",
    "test_accuracy = correct / total # Calculate accuracy\n",
    "print(f\" Test Accuracy: {test_accuracy * 100:.2f}%\") # Print the final test accuracy\n",
    "\n",
    "#  Log to wandb\n",
    "wandb.log({\"test_accuracy\": test_accuracy * 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to unnormalize and convert a tensor image to NumPy for visualization\n",
    "def imshow(img):\n",
    "    img = img.cpu().numpy().transpose((1, 2, 0)) # Move to CPU\n",
    "    mean = np.array([0.485, 0.456, 0.406]) # Mean used in normalization\n",
    "    std = np.array([0.229, 0.224, 0.225]) # Std used in normalization\n",
    "    img = std * img + mean  # Unnormalize the image\n",
    "    img = np.clip(img, 0, 1) # Clip pixel values to [0, 1]\n",
    "    return img\n",
    "\n",
    "# Function to display model predictions\n",
    "def show_predictions(model, dataloader, class_names, num_images=30):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    images_shown = 0 # Counter for images shown\n",
    "    plt.figure(figsize=(12, 20)) # Create a big figure for showing images\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader): # Loop through data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # Move to device\n",
    "            outputs = model(inputs)  # Get model predictions\n",
    "            _, preds = torch.max(outputs, 1) # Get class with highest score\n",
    "            for j in range(inputs.size(0)): # Loop through batch\n",
    "                if images_shown >= num_images: # Stop if enough images shown\n",
    "                    break\n",
    "                img = imshow(inputs[j]) # Convert tensor to image\n",
    "                plt.subplot(10, 3, images_shown + 1) # Create subplot (10 rows, 3 columns)\n",
    "                plt.imshow(img) # Show image\n",
    "                plt.title(f\"Pred: {class_names[preds[j]]}\\nTrue: {class_names[labels[j]]}\", fontsize=8) # Title with predicted and true label\n",
    "                plt.axis('off') # Hide axes\n",
    "                images_shown += 1 # Update image counter\n",
    "            if images_shown >= num_images:  # Break outer loop too if done\n",
    "                break\n",
    "    \n",
    "    plt.tight_layout() # Adjust layout to prevent overlap\n",
    "    plt.savefig(\"predictions.png\", bbox_inches='tight') # Save figure as PNG file\n",
    "    plt.close()  #  Close the plot so it's fully written\n",
    "    wandb.log({\"sample_predictions\": wandb.Image(\"predictions.png\")}) # Log image to wandb\n",
    "    \n",
    "\n",
    "\n",
    "#  Display 10x3 predictions from test set\n",
    "show_predictions(best_model, test_loader, train_data.classes, num_images=30)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
